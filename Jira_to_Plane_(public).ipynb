{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Plane variables"
      ],
      "metadata": {
        "id": "hnjBOfEQIIqS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoEmoLl7ICXu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define your Plane variables : change this with your values\n",
        "workspace_slug = \"your_workspace_name\"\n",
        "domain = \"your workspace domain : e.g sub.domain.com\"\n",
        "api_key = \"plane_api_hexa\"\n",
        "headers = {\"x-api-key\": api_key}"
      ],
      "metadata": {
        "id": "QJwzeKkEdjuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# table containing user names as per Jira (Assignee), and user ids as per Plane.\n",
        "# in plane, user ids can be retrieved by created a dummy project, add all users as members, create tasks and assign one to each user,\n",
        "# and use the API to see Assignees\n",
        "# change this with your values\n",
        "user_table = { \"User 1 as per Jira Assigne column in exports\" : \"user_1_id_in_plane\"}"
      ],
      "metadata": {
        "id": "sMQQxh9ZduQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Table containing Jira assignees/users ids and Jira assignes/users names : needed to parse comments in Jira\n",
        "# put a default users for comments for unknown members ( e.g : former employee)\n",
        "# change this with your values\n",
        "jira_user_table = {\n",
        "    \"default\" : \"your default user name\",\n",
        "    \"user_1_id_in_jira\" : \"user 1\",\n",
        "}"
      ],
      "metadata": {
        "id": "zlmf7KWOcUTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map priority levels in Jira versus Plane (keys are jira's, values are plane's)\n",
        "# don't change it if this default mapping is fine\n",
        "priority_table = {\"Lowest\" : \"low\", \"Low\" : \"low\", \"Medium\" : \"medium\", \"High\": \"high\", \"Highest\": \"urgent\" }"
      ],
      "metadata": {
        "id": "p7CckMHNJjGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correspondance tables for states between jira & planes. Keys are jira states, values are Plane states label\n",
        "# don't change it if this default mapping is fine\n",
        "state_correspondance_table = {\"Done\" : \"Done\", \"In Progress\" : \"In Progress\", \"To Do\": \"Todo\", \"Canceled\" : \"Cancelled\", \"Closed\" : \"Done\"}"
      ],
      "metadata": {
        "id": "gVzckKOPoW4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and variables to manage attachments with GDrive"
      ],
      "metadata": {
        "id": "3fxKxyBs8t3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import here (via a file) your latest cookies for jira website from browser using an extension such as Cookie Editor\n",
        "# it will be needed to access Jira attachments\n",
        "# update the cookie_filename accordingly\n",
        "cookie_filename = '/content/atlassian_cookie.json'\n",
        "\n",
        "with open(cookie_filename) as f:\n",
        "    cookie = json.load(f)\n",
        "\n",
        "cookies_dict = {cookie['name']: cookie['value'] for cookie in cookie}"
      ],
      "metadata": {
        "id": "LzB4xFlmQSO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports related to using GDrive as destination for attachment (needed until attachment upload is available and documented in Plane API)\n",
        "from google.colab import drive\n",
        "from googleapiclient.discovery import build\n",
        "from io import BytesIO\n",
        "from google.colab import auth"
      ],
      "metadata": {
        "id": "SeM9Ht_XP9lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init : mount google drive to push images from Jira\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Replace with your actual folder path in Google Drive where you want to store attachments\n",
        "# The folder should exist : create it before running the cell\n",
        "# it can be a shared drive\n",
        "# change this with your values\n",
        "gdrive_folder_path = '/content/gdrive/Shareddrives/your_attachment_destination/'\n",
        "%cd $gdrive_folder_path"
      ],
      "metadata": {
        "id": "LSxqeOUmRz9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import / create in Plane: functions (run as is)"
      ],
      "metadata": {
        "id": "eJnqiwNYdUc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def send_request(method, url, headers,*arg):\n",
        "    try:\n",
        "        payload = arg[0]\n",
        "        response = requests.request(method, url, headers=headers, json=payload)\n",
        "        print(response)\n",
        "        if response.status_code in [200, 201, 204]:\n",
        "            response = json.loads(response.text)\n",
        "            return response\n",
        "        elif response.status_code == 429:\n",
        "            print(\"Pausing for one minute\")\n",
        "            time.sleep(60)\n",
        "            response = requests.request(method, url, headers=headers, json=payload)\n",
        "            response = json.loads(response.text)\n",
        "            return response\n",
        "        else:\n",
        "            print('Error : ', response, response.text)\n",
        "    except:\n",
        "        response = requests.request(method, url, headers=headers)\n",
        "        print(response)\n",
        "        if response.status_code in [200, 201, 204]:\n",
        "            response = json.loads(response.text)\n",
        "            return response\n",
        "        elif response.status_code == 429:\n",
        "            print(\"Pausing for one minute\")\n",
        "            time.sleep(60)\n",
        "            response = requests.request(method, url, headers=headers)\n",
        "            response = json.loads(response.text)\n",
        "            return response\n",
        "        else:\n",
        "            print('Error : ', response, response.text)"
      ],
      "metadata": {
        "id": "AfhTmu16hyw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to handle module creation corresponding to Jira Epics\n",
        "# assumes df contains only Epics\n",
        "# NOT USED ANYMORE\n",
        "def create_module(domain, workspace_slug, project_id, df, module_table):\n",
        "    #create modules in Plane based on Jira Epics info. We use keys and not ids as EPIC are linked via keys in the jira export\n",
        "    #some exports do not use Custom Epic links, only parents => need for a v2\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/modules/\"\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        payload = {\n",
        "            \"name\": row['Summary'],\n",
        "            \"status\": 'in-progress',\n",
        "            }\n",
        "        description = desc_to_html(row['Description'])\n",
        "        if description != \"\":\n",
        "            payload['description_html'] = description\n",
        "        if get_assignee(row['Assignee']) != \"\":\n",
        "            payload[\"lead\"] = [get_assignee(row['Assignee'])]\n",
        "        response = send_request(\"POST\", url, headers, payload)\n",
        "        module_table[row['Issue key']]=response['id']\n",
        "\n",
        "    return module_table\n",
        "\n",
        "\n",
        "# function to handle module creation corresponding to Jira Epics\n",
        "# assumes df contains only Epics\n",
        "def create_module_v2(domain, workspace_slug, project_id, df, module_table):\n",
        "    #create modules in Plane based on Jira Epics info. We use ids as EPIC will be linked to issues via parent ids\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/modules/\"\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        payload = {\n",
        "            \"name\": row['Summary'],\n",
        "            \"status\": 'in-progress',\n",
        "            }\n",
        "        description = desc_to_html(row['Description'])\n",
        "        if description != \"\":\n",
        "            payload['description_html'] = description\n",
        "        if get_assignee(row['Assignee']) != \"\":\n",
        "            payload[\"lead\"] = [get_assignee(row['Assignee'])]\n",
        "        response = send_request(\"POST\", url, headers, payload)\n",
        "        module_table[row['Issue id']]=response['id']\n",
        "\n",
        "    return module_table"
      ],
      "metadata": {
        "id": "6C6BjM0dA5sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to handle cycle creation corresponding to Jira sprints\n",
        "\n",
        "def create_cycle(domain, workspace_slug, project_id, sprint_table):\n",
        "    #create cycles in Plane based on Jira sprints info\n",
        "    # NOT USED ANYMORE\n",
        "\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/cycles/\"\n",
        "\n",
        "    cycle_table = {}\n",
        "    for i in range(len(sprint_table)):\n",
        "        payload = {\"name\": sprint_table[i]['name'],\n",
        "                \"start_date\" : sprint_table[i]['startDate'].strftime('%Y-%m-%d'),\n",
        "                \"end_date\": sprint_table[i]['endDate'].strftime('%Y-%m-%d')\n",
        "                }\n",
        "        response = send_request(\"POST\", url, headers, payload)\n",
        "        cycle_table[sprint_table[i]['name']]=response['id']\n",
        "\n",
        "    return cycle_table\n",
        "\n",
        "def create_cycle_no_end_date(domain, workspace_slug, project_id, cycle_table, sprint_table):\n",
        "    #create cycles in Plane based on Jira sprints info\n",
        "    #expect sprint_table to be a list of (only one) sprint\n",
        "    #update cycle_table instead of creating one from scratch\n",
        "\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/cycles/\"\n",
        "\n",
        "    tomorrow = datetime.datetime.now() + datetime.timedelta(days=1)\n",
        "    #cycle_table = {}\n",
        "    for i in range(len(sprint_table)):\n",
        "        payload = {\"name\": sprint_table[i]['name'],\n",
        "                \"start_date\" : sprint_table[i]['startDate'].strftime('%Y-%m-%d'),\n",
        "                \"end_date\" : tomorrow.strftime('%Y-%m-%d')\n",
        "                }\n",
        "        response = send_request(\"POST\", url,headers,payload)\n",
        "        print('Cycle creation:')\n",
        "        print(response)\n",
        "        cycle_table[sprint_table[i]['name']]=response['id']\n",
        "\n",
        "    return cycle_table\n",
        "\n",
        "def update_one_cycle_end_date(domain, workspace_slug, project_id, cycle_table, sprint_table):\n",
        "    #update cycle end date\n",
        "    #except sprint_table to be a list of only one sprint\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/cycles/{cycle_table[sprint_table[0]['name']]}/\"\n",
        "    payload = {\n",
        "        \"name\": sprint_table[0]['name'],\n",
        "        \"start_date\" : sprint_table[0]['startDate'].strftime('%Y-%m-%d'),\n",
        "        \"end_date\" : sprint_table[0]['endDate'].strftime('%Y-%m-%d')\n",
        "        }\n",
        "    response = send_request(\"PATCH\", url,headers, payload)\n",
        "    print('Cycle update:')\n",
        "    print(response)\n",
        "\n",
        "\n",
        "def read_all_cycle(domain, workspace_slug, project_id):\n",
        "    # not fully tested - not used\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/cycles/\"\n",
        "\n",
        "    cycle_table = {}\n",
        "\n",
        "    response = send_request(\"GET\", url, headers)\n",
        "\n",
        "    #print(response)\n",
        "    for i in range(len(response['results'])):\n",
        "        cycle_table[response['results'][i]['name']]= response['results'][i]['id']\n",
        "    return cycle_table\n"
      ],
      "metadata": {
        "id": "yEUlroDP3Y1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get state list, complete state correspondance dict\n",
        "def complete_state_dict(domain, workspace_slug, project_id):\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/states/\"\n",
        "\n",
        "    response = send_request(\"GET\", url, headers)\n",
        "\n",
        "    state_dict = {}\n",
        "\n",
        "    for items in response[\"results\"]:\n",
        "        state_dict[items['name']] = items['id']\n",
        "    print(state_dict)\n",
        "\n",
        "    for k,v in state_correspondance_table.items():\n",
        "        project_jira_state_dict[k] = state_dict[v]\n",
        "    #project_jira_state_dict['Done'] = state_dict['Done']\n",
        "    #project_jira_state_dict['In Progress'] = state_dict['In Progress']\n",
        "    #project_jira_state_dict['To Do'] = state_dict['Todo']\n",
        "    #project_jira_state_dict['Canceled'] = state_dict['Cancelled']\n",
        "    print(project_jira_state_dict)\n",
        "    return project_jira_state_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "4vTHBXIp9G8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get project Labels (create a Label Bug, in red, if needed)\n",
        "def create_or_get_label_bug(domain, workspace_slug, project_id):\n",
        "    label_bug = \"\"\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/labels/\"\n",
        "\n",
        "    response = send_request(\"GET\", url, headers)\n",
        "\n",
        "    try:\n",
        "        for items in response['results']:\n",
        "            if items['name'] == 'Bug' or items['name'] == 'bug':\n",
        "                label_bug = items['id']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if label_bug == \"\":\n",
        "        payload = {\"name\": \"Bug\", \"color\": '#eb144c'}\n",
        "        response = send_request(\"POST\", url, headers, payload)\n",
        "        label_bug = response['id']\n",
        "    return label_bug\n"
      ],
      "metadata": {
        "id": "qMEwTPxwXu59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assignee(item):\n",
        "    try:\n",
        "        return user_table[item]\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def desc_to_html(description):\n",
        "    html_desc= \"\"\n",
        "    if type(description) is not str:\n",
        "        return \"\"\n",
        "    for lines in description.splitlines():\n",
        "        html_desc += \"<p>\" + lines + \"</p>\"\n",
        "    return html_desc\n",
        "\n",
        "def build_comment_payload(comments):\n",
        "    #print(comments)\n",
        "    # first version : assumes only one comment is present. assumes comments does not include ';'\n",
        "    split_comments = comments.split(';')\n",
        "    #print(split_comments)\n",
        "    # O should be timestamp, 1 user id in jira, 2 actual comment\n",
        "    try:\n",
        "        payload = {\n",
        "            'comment_html' : desc_to_html(split_comments[2]),\n",
        "            'actor' : user_table[jira_user_table[split_comments[1]]]\n",
        "        }\n",
        "    except KeyError:\n",
        "        payload = {\n",
        "            'comment_html' : desc_to_html(split_comments[2]),\n",
        "            'actor' : user_table[jira_user_table['default']]\n",
        "        }\n",
        "    return payload\n",
        "\n",
        "def find_max_sprint_nb_in_df(df):\n",
        "    # not needed anymore\n",
        "    columns = df.columns.tolist()\n",
        "    sprint_column = []\n",
        "    for column in columns:\n",
        "        if column.startswith('Sprint'):\n",
        "            sprint_column.append(column)\n",
        "    return len(sprint_column)\n",
        "\n",
        "def assess_sprint_nb(row, max_sprint):\n",
        "    # not needed anymore\n",
        "    for count in range(max_sprint-1, 0, -1):\n",
        "        if type(row[f'Sprint.{count}']) is str and row[f'Sprint.{count}'] != '':\n",
        "            return row[f'Sprint.{count}']\n",
        "\n",
        "    if type(row['Sprint']) is str and row['Sprint']!= '':\n",
        "        return row['Sprint']\n",
        "    else:\n",
        "        #print(row)\n",
        "        return None\n",
        "\n",
        "def add_lastsprint_df(df):\n",
        "    columns = df.columns.tolist()\n",
        "    sprint_column = []\n",
        "    for column in columns:\n",
        "        if column.startswith('Sprint'):\n",
        "            sprint_column.append(column)\n",
        "    df['Last Sprint'] = df[sprint_column].max(axis=1)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "mfV_sJDxWv5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create issues corresponding to Jira issues, bugs,tasks or sub-tasks and assign them to the proper cycle\n",
        "def create_issues(domain, workspace_slug, project_id, df, project_jira_state_dict, label_bug, issue_id_table):\n",
        "\n",
        "    url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/\"\n",
        "\n",
        "    # create issues without sprint, comments and parent relationships\n",
        "\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        payload = {\n",
        "            \"name\": row['Summary'],\n",
        "            \"state\": project_jira_state_dict[row['Status']],\n",
        "            \"priority\" : priority_table[row['Priority']]\n",
        "            }\n",
        "        description = desc_to_html(row['Description'])\n",
        "        if description != \"\":\n",
        "            payload['description_html'] = description\n",
        "        if get_assignee(row['Assignee']) != \"\":\n",
        "            payload[\"assignees\"] = [get_assignee(row['Assignee'])]\n",
        "        if row['Issue Type'] == 'Bug':\n",
        "            payload['labels'] = [label_bug]\n",
        "        #print(payload)\n",
        "        response = send_request(\"POST\", url, headers, payload )\n",
        "        issue_id_table[row['Issue id']]= response['id']\n",
        "    return issue_id_table\n",
        "\n",
        "def add_comments(domain, wokspace_slug, project_id, df, issue_id_table):\n",
        "    # add comments. Comments may not exist in the df, so check first\n",
        "    if 'Comment' not in df.columns:\n",
        "        return None\n",
        "    count = 0\n",
        "    for columns in df.columns:\n",
        "        if columns.startswith('Comment'):\n",
        "            count += 1\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if type(row['Comment']) is str and row['Comment'] != '':\n",
        "            url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/comments/\"\n",
        "            payload = build_comment_payload(row['Comment'])\n",
        "            #print(payload)\n",
        "            response = send_request(\"POST\", url, headers, payload)\n",
        "        for i in range(1, count):\n",
        "            if type(row[f'Comment.{i}']) is str and row[f'Comment.{i}'] != '':\n",
        "                url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/comments/\"\n",
        "                payload = build_comment_payload(row[f'Comment.{i}'])\n",
        "                #print(payload)\n",
        "                response = send_request(\"POST\", url, headers, payload)\n",
        "\n",
        "def add_issue_key_comments(domain ,workspace_slug, project_id, df, issue_id_table, commentator_id):\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/comments/\"\n",
        "        payload = build_comment_payload(f\"__;{commentator_id};JIRA Issue key : {row['Issue key']}\")\n",
        "        print(payload)\n",
        "        response = send_request(\"POST\", url, headers, payload)\n",
        "\n",
        "\n",
        "def associate_issues_to_cycles(domain, workspace_slug, project_id, df,issue_id_table, cycle_table):\n",
        "    # associate issues and cycles.\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if row['Last Sprint'] != '':\n",
        "            row_sprint = cycle_table[row['Last Sprint']]\n",
        "            url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/cycles/{row_sprint}/cycle-issues/\"\n",
        "            payload = {\n",
        "                \"issues\" : [issue_id_table[row['Issue id']]]\n",
        "            }\n",
        "            response = send_request(\"POST\", url,headers, payload)\n",
        "            print(response)\n",
        "\n",
        "def manage_parent_relationships(domain, workspace_slug, project_id, df, issue_id_table):\n",
        "    # manage parent relationships. Parent may not exist in the df, so check first\n",
        "    # expect df_issues as input\n",
        "    if 'Parent' not in df.columns:\n",
        "        return None\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if type(row['Parent']) is str and row['Parent'] != '':\n",
        "            try:\n",
        "                url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/\"\n",
        "                payload = {\"parent\": issue_id_table[row['Parent']]}\n",
        "                response = send_request(\"PATCH\", url,headers, payload)\n",
        "            except KeyError:\n",
        "                #KeyError may occur if this function is used with df_issues and the parent is an EPIC => ignore in that case, since Epic are managed via modules already\n",
        "                pass\n",
        "\n",
        "\n",
        "def manage_parent_and_module_relationships(domain, workspace_slug, project_id, df, issue_id_table, module_table):\n",
        "    # manage parent and module relationships. Expecting df_issues in input\n",
        "    if 'Parent' not in df.columns:\n",
        "        return None\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if type(row['Parent']) is str and row['Parent'] != '':\n",
        "            if row['Parent'] in list(module_table.keys()):\n",
        "                url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/modules/{module_table[row['Parent']]}/module-issues/\"\n",
        "                payload = {\n",
        "                    \"issues\" : [issue_id_table[row['Issue id']]]\n",
        "                    }\n",
        "                response = send_request(\"POST\", url,headers, payload)\n",
        "            else:\n",
        "                url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/\"\n",
        "                payload = {\"parent\": issue_id_table[row['Parent']]}\n",
        "                response = send_request(\"PATCH\", url,headers, payload)\n",
        "\n",
        "\n",
        "\n",
        "def associate_issue_to_modules(domain, workspace_slug, project_id, df, issue_id_table, module_table):\n",
        "    # Custom field (Epic Link) may not exist in the df, so check first\n",
        "    if 'Custom field (Epic Link)' not in df.columns:\n",
        "        return None\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if row['Custom field (Epic Link)'] != '':\n",
        "            url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/modules/{module_table[row['Custom field (Epic Link)']]}/module-issues/\"\n",
        "            payload = {\n",
        "                \"issues\" : [issue_id_table[row['Issue id']]]\n",
        "            }\n",
        "            response = send_request(\"POST\", url,headers, payload)"
      ],
      "metadata": {
        "id": "NloCMEwE7pZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manage attachments\n",
        "\n",
        "def get_file_id(file_name, drive_service):\n",
        "    \"\"\"\n",
        "    Retrieves the file ID of an existing file on Google Drive by its name.\n",
        "\n",
        "    Args:\n",
        "        file_name: The name of the file to search for.\n",
        "        drive_service: The authenticated Google Drive API service object.\n",
        "\n",
        "    Returns:\n",
        "        The file ID of the file if found, or None if the file does not exist.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Search for the file by name in Google Drive\n",
        "        results = drive_service.files().list(\n",
        "            q=f\"name='{file_name}' and trashed=false\",\n",
        "            spaces='drive',\n",
        "            fields='files(id, name)',\n",
        "            pageSize=10,\n",
        "            includeItemsFromAllDrives=True,  # Search across all drives\n",
        "            supportsAllDrives=True  # Enable support for shared drives\n",
        "        ).execute()\n",
        "\n",
        "        # Extract the files list from the response\n",
        "        files = results.get('files', [])\n",
        "\n",
        "        # Check if any files match the name\n",
        "        if not files:\n",
        "            print(f\"No file found with the name '{file_name}'.\")\n",
        "            return None\n",
        "\n",
        "        # If there are multiple matches, return the first one\n",
        "        file_id = files[0].get('id')\n",
        "        print(f\"Found file: {files[0].get('name')} (ID: {file_id})\")\n",
        "        return file_id\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving file ID: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def upload_file_to_gdrive(file_url, filename):\n",
        "    \"\"\"Uploads a file from a URL to Google Drive and returns the shareable link.\n",
        "\n",
        "    Args:\n",
        "        file_url: The URL of the file to download.\n",
        "        filename: The desired filename in Google Drive.\n",
        "\n",
        "    Returns:\n",
        "        The shareable link of the uploaded file, or None if upload fails.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(file_url, stream=True, cookies = cookies_dict)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "        file_content = BytesIO(response.content)\n",
        "\n",
        "        file_content.seek(0)\n",
        "\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(file_content.read())\n",
        "\n",
        "        # Authenticate with Google Drive API\n",
        "\n",
        "        #file_metadata = {\n",
        "        #    'name': filename,\n",
        "        #    'parents': [gdrive_folder_path.split('/')[-1]]  # Assuming the last part of the path is the folder ID\n",
        "        #}\n",
        "        #media = MediaIoBaseUpload(file_content, mimetype='application/octet-stream', resumable=True)\n",
        "\n",
        "        #file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        #file_id = file.get('id')\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading file from URL: {e}\")\n",
        "        return None\n",
        "\n",
        "def update_permission_get_link(filename):\n",
        "    try:\n",
        "        drive_service = build('drive', 'v3')\n",
        "        # Permissions\n",
        "        permission = {\n",
        "            'type': 'anyone',\n",
        "            'role': 'reader'\n",
        "        }\n",
        "        file_id = get_file_id(filename, drive_service)\n",
        "        drive_service.permissions().create(fileId=file_id, body=permission, supportsAllDrives=True).execute()\n",
        "\n",
        "        # Get shareable link\n",
        "        shareable_link = drive_service.files().get(fileId=file_id, fields='webViewLink', supportsAllDrives=True).execute().get('webViewLink')\n",
        "        return shareable_link\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading to Google Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "# function to create new attachments columns in df, new Gdrive links and update it with new GDrive links\n",
        "\n",
        "def push_attachments_gdrive_update_df(df):\n",
        "    count = 0\n",
        "    if 'Attachment' not in df.columns:\n",
        "        return df\n",
        "    for columns in df.columns:\n",
        "        if columns.startswith('Attachment'):\n",
        "            df['GDrive.' + str(columns)] = \"\"\n",
        "            count += 1\n",
        "    #print(df.columns.tolist())\n",
        "    # first create all files in GDrive, then update all permissions and get links\n",
        "    # otherwise, we would neet to wait several seconds between file creation and link retrieval\n",
        "    start_time = time.time()\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if type(row['Attachment']) is str and row['Attachment'] != '':\n",
        "            filename = row['Attachment'].split(';')[2]\n",
        "            filelink = row['Attachment'].split(';')[3]\n",
        "            upload_file_to_gdrive(filelink, filename)\n",
        "        for i in range(1, count):\n",
        "            if type(row['Attachment.' + str(i)]) is str and row['Attachment.' + str(i)] != '':\n",
        "                filename = row['Attachment.' + str(i)].split(';')[2]\n",
        "                filelink = row['Attachment.' + str(i)].split(';')[3]\n",
        "                upload_file_to_gdrive(filelink, filename)\n",
        "    end_time = time.time()\n",
        "    if end_time - start_time < 15:\n",
        "        time.sleep(15-(end_time - start_time))\n",
        "    for index, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if type(row['Attachment']) is str and row['Attachment'] != '':\n",
        "            filename = row['Attachment'].split(';')[2]\n",
        "            gdrive_link = update_permission_get_link(filename)\n",
        "            df.at[index, 'GDrive.Attachment'] = gdrive_link\n",
        "        for i in range(1, count):\n",
        "            if type(row['Attachment.' + str(i)]) is str and row['Attachment.' + str(i)] != '':\n",
        "                filename = row['Attachment.' + str(i)].split(';')[2]\n",
        "                gdrive_link = update_permission_get_link(filename)\n",
        "                df.at[index, 'GDrive.Attachment.' + str(i)] = gdrive_link\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "55z8Epy-hDlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_comments_attachments(domain, workspace_slug, project_id, df):\n",
        "    if 'GDrive.Attachment' not in df.columns:\n",
        "        return None\n",
        "    count = 0\n",
        "    for columns in df.columns:\n",
        "        if columns.startswith('GDrive'):\n",
        "            count += 1\n",
        "    for _, row in df.sort_values(by=[\"Issue id\"]).iterrows():\n",
        "        if type(row['GDrive.Attachment']) is str and row['GDrive.Attachment'] != '':\n",
        "            url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/comments/\"\n",
        "            file_name = row['Attachment'].split(';')[2]\n",
        "            file_link = row['GDrive.Attachment']\n",
        "            payload = {\n",
        "                \"comment_html\": f\"<p><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" class=\\\"text-custom-primary-300 underline underline-offset-[3px] hover:text-custom-primary-500 transition-colors cursor-pointer\\\" href=\\\"{file_link}\\\">{file_name}</a></p>\"\n",
        "                }\n",
        "            response = send_request(\"POST\", url, headers, payload)\n",
        "        for i in range(1, count):\n",
        "            if type(row['GDrive.Attachment.' + str(i)]) is str and row['GDrive.Attachment.' + str(i)] != '':\n",
        "                url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/issues/{issue_id_table[row['Issue id']]}/comments/\"\n",
        "                file_name = row['Attachment.' + str(i)].split(';')[2]\n",
        "                file_link = row['GDrive.Attachment.' + str(i)]\n",
        "                payload = {\n",
        "                    \"comment_html\": f\"<p><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer nofollow\\\" class=\\\"text-custom-primary-300 underline underline-offset-[3px] hover:text-custom-primary-500 transition-colors cursor-pointer\\\" href=\\\"{file_link}\\\">{file_name}</a></p>\"\n",
        "                    }\n",
        "                response = send_request(\"POST\", url, headers, payload)\n"
      ],
      "metadata": {
        "id": "zBFVtVtJS4xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export one project from Jira"
      ],
      "metadata": {
        "id": "ZWEiaoU7IYfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure there is no future sprint with issues in it : they will be ignored\n",
        "\n",
        "# get json of sprints using https://CompanyName.atlassian.net/rest/agile/1.0/board/xx/sprint\n",
        "# board nb (xx) is visible in all urls of a given project\n",
        "# Either copy and paste json content here :\n",
        "\n",
        "#sprint_json = json.loads(\"\"\"{ your json here }\"\"\")\n",
        "\n",
        "# or, if you have already added cookies to connect to atlassian for the attachments\n",
        "# set url :\n",
        "url = \"https://<your cpy domain name in jira>.atlassian.net/rest/agile/1.0/board/2/sprint\"\n",
        "\n",
        "#requests.request(method, url, headers=headers, json=payload)\n",
        "response = requests.get(url, cookies = cookies_dict)\n",
        "sprint_json = json.loads(response.text)\n",
        "\n",
        "\n",
        "# creates simplified sprint table\n",
        "# excludes 'future' sprint, assuming there is no issues in there\n",
        "sprint_table = []\n",
        "for sprints_count in range(sprint_json['total']):\n",
        "    if sprint_json['values'][sprints_count]['state'] != 'future':\n",
        "        sprint_table.append({'name': sprint_json['values'][sprints_count]['name'], 'startDate' : datetime.datetime.fromisoformat(sprint_json['values'][sprints_count]['startDate'].rstrip('Z')), 'endDate' : datetime.datetime.fromisoformat(sprint_json['values'][sprints_count]['endDate'].rstrip('Z'))})\n",
        "\n",
        "print(sprint_table)"
      ],
      "metadata": {
        "id": "eT6XEVuIId1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import project csv\n",
        "# use the export function in the issue view in Jira : chose export excel csv (all fields)\n",
        "# change the filename accordingly\n",
        "\n",
        "filename ='/content/Jira Export Excel CSV (all fields) timestamp.csv'\n",
        "\n",
        "types = defaultdict(lambda: str)\n",
        "with open(filename, 'r') as f:\n",
        "    df = pd.read_csv(f,dtype=types, keep_default_na=False)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IEIWa91eSDVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This gives you the list of members associated with your project in Jira\n",
        "project_user_list = set(df['Assignee'].tolist())\n",
        "print(project_user_list)"
      ],
      "metadata": {
        "id": "lv-Dly7rePZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the project state dict, will be updated with actual state id, depending on your\n",
        "# state correspondance table defined above\n",
        "project_jira_state_list = set(df['Status'].tolist())\n",
        "project_jira_state_dict = {}\n",
        "for item in project_jira_state_list:\n",
        "    project_jira_state_dict[item] = 'tbd'\n",
        "print(project_jira_state_dict)"
      ],
      "metadata": {
        "id": "znICv_pS9Z0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell tells you if there are attachments to manage in your Jira project (empty list means no attachment)\n",
        "\n",
        "[column_names for column_names in df.columns.tolist() if column_names.startswith('Attachment')]"
      ],
      "metadata": {
        "id": "aUa6f5tdIPN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import / create in Plane : execution"
      ],
      "metadata": {
        "id": "IJufRd7cwXf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST create project in Plane UI and ADD NECESSARY MEMBERS (C.F. list above)\n",
        "# member addition cannot be made via API\n",
        "# THEN enter project id => can be found in project view url, format looks like example below\n",
        "project_id = \"d7b51669-a4a4-4d45-987c-1f93458d3939\""
      ],
      "metadata": {
        "id": "V6K8eiEHdZuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get project details (this will allow you to check your project id is ok, check number of members)\n",
        "\n",
        "url = f\"https://{domain}/api/v1/workspaces/{workspace_slug}/projects/{project_id}/\"\n",
        "\n",
        "response = requests.request(\"GET\", url, headers=headers)\n",
        "response = json.loads(response.text)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "vcYTAYdokYT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare data : run as is\n",
        "\n",
        "#assumes sprint_table & df are created\n",
        "\n",
        "project_jira_state_dict = complete_state_dict(domain, workspace_slug, project_id)\n",
        "label_bug = create_or_get_label_bug(domain, workspace_slug, project_id)\n",
        "\n",
        "cycle_table = {}\n",
        "issue_id_table = {}\n",
        "module_table = {}\n",
        "\n",
        "df = add_lastsprint_df(df)\n",
        "\n",
        "# define what you consider issues in Plane. By default Bug will be issues flagged with a particular Label\n",
        "# Story & Task will be delt without distinction\n",
        "# Sub task will become subtasks thanks to parenting\n",
        "# epic will be become modules\n",
        "df_issues = df[df['Issue Type'].isin(['Story', 'Task', 'Sub-task', 'Bug', 'Subtask'])]\n",
        "df_epic = df[df['Issue Type'] == 'Epic']"
      ],
      "metadata": {
        "id": "Oe8TjLAm9vKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create modules, if any : run as is\n",
        "module_table = create_module_v2(domain, workspace_slug, project_id, df_epic, module_table)"
      ],
      "metadata": {
        "id": "ry_4TdN892oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create issues : run as is\n",
        "\n",
        "# first : manage the case where there are no sprints in the project\n",
        "if 'Sprint' not in df.columns:\n",
        "    issue_id_table = create_issues(domain, workspace_slug, project_id, df_issues, project_jira_state_dict, label_bug, issue_id_table)\n",
        "\n",
        "else:\n",
        "    # create issues without sprints first :\n",
        "    issue_id_table = create_issues(domain, workspace_slug, project_id, df_issues[df_issues['Last Sprint']==''], project_jira_state_dict, label_bug, issue_id_table)\n",
        "\n",
        "    # create issues in sprint, from sprint chronological order\n",
        "    # first : create one cycle without end date, then create issues, associate them, then add closing dates\n",
        "    for sprint in sprint_table:\n",
        "        cycle_table = create_cycle_no_end_date(domain, workspace_slug, project_id, cycle_table, [sprint])\n",
        "        issue_id_table = create_issues(domain, workspace_slug, project_id, df_issues[df_issues['Last Sprint']==sprint['name']], project_jira_state_dict, label_bug, issue_id_table)\n",
        "        associate_issues_to_cycles(domain, workspace_slug, project_id, df_issues[df_issues['Last Sprint']==sprint['name']], issue_id_table, cycle_table)\n",
        "        update_one_cycle_end_date(domain, workspace_slug, project_id, cycle_table, [sprint])"
      ],
      "metadata": {
        "id": "UAJzrcV397gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add comments : run as is\n",
        "\n",
        "# Add all comments from Jira\n",
        "add_comments(domain, workspace_slug, project_id, df_issues, issue_id_table)\n",
        "\n",
        "# add previous (Jira) issue key as additional comment. Provide a valid commentator id as input\n",
        "add_issue_key_comments(domain ,workspace_slug, project_id, df_issues, issue_id_table, commentator_id = '5e1d869d010b260ca879be6f')"
      ],
      "metadata": {
        "id": "B81zfyiCvAhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manage all parent relationships (sub tasks, and epic) : run as is\n",
        "manage_parent_and_module_relationships(domain, workspace_slug, project_id, df_issues, issue_id_table, module_table)"
      ],
      "metadata": {
        "id": "KF4HX_WE-HVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create attachments from jira in GDrive : run as is\n",
        "df= push_attachments_gdrive_update_df(df)"
      ],
      "metadata": {
        "id": "0YiX55bTsI-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create attachment links as comments in Plane  : run as is\n",
        "create_comments_attachments(domain, workspace_slug, project_id, df)"
      ],
      "metadata": {
        "id": "gNnoyK5CsRO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}